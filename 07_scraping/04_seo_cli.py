import requests
import argparse

from bs4 import BeautifulSoup
from urllib.parse import urljoin
import requests

parser = argparse.ArgumentParser(description="web scraping to check SEO for a guiven URL")
parser.add_argument('url', type=str, help='The URL of the site you want to scrape and check')
args = parser.parse_args()
url=args.url

url = 'https://www.apple.com/es/shop/buy-mac/macbook-air/'
headers = {
    'User-Agent': 'Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; Googlebot/2.1; +http://www.google.com/bot.html) Chrome/131.0.0 Safari/537.36'
} # utilizar vpn para hacer scraping
response = requests.get(url, headers=headers)

if response.status_code == 200:
    print(' La peticion fue exitosa')

    soup = BeautifulSoup(response.text, 'html.parser')

    print(f"\033[34mRevisando la página: {url}\33[0m]" )
    print("\nSEO básico:")

    titulo_pagina = soup.title.string

    if titulo_pagina:
        print(f"\033 [44mEl título de la página es: {titulo_pagina}\33[0m]")
        if len(titulo_pagina) < 70:
            print("\033 [32mEl título de la página tiene una longitud adecuada\33[0m]")
        else:
            print(" El título de la página es DEMASIDO largo")

# extrae todos los titulos h1
titulos = [titulo.string for titulo in soup.find_all('h1')]
if not titulos:
    print("\033[31m No se encontraron títulos h1 en la página\033[0m")
elif len(titulos) > 1:
    print("\033[31m Hay más de un título h1 en la página\033[0m")
    for titulo in titulos:
        print(titulo)
    else:
        print("\033[32m Hay un título h1 en la página\033[0m")
